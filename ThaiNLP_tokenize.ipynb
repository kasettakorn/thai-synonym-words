{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ThaiNLP_tokenize.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNWsSbFkiYQEHSy0g5vfyDX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kasettakorn/thai-synonym-words/blob/master/ThaiNLP_tokenize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcTgI-f1jUXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pythainlp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0ahGPYakTVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pythainlp.tokenize import word_tokenize\n",
        "text='ผมรักคุณนะครับโอเคบ่พวกเราเป็นคนไทยรักภาษาไทยภาษาบ้านเกิด'\n",
        "a=word_tokenize(text,engine='icu')\n",
        "print(a)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swUdwX3-yjib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pythainlp.tokenize import syllable_tokenize\n",
        "n = eval(input(\"Number of words: \"))\n",
        "words = []\n",
        "for i in range(0, n):\n",
        "    word = input(\"words #\"+str(i+1)+\": \")\n",
        "    words.append(word)\n",
        "print(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lyl3blmHG1e1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "a2d42705-dbc1-4198-b046-4acff812d6d4"
      },
      "source": [
        "thai_alphabet_cluster = ['ก', 'ขฃ', 'คฅฆ', 'ง', 'จ', 'ฉ', 'ชฌ', 'ซ', 'ญย', 'ฎด', 'ฏต', 'ฐถ', 'ฑฒทธ', 'ณน', 'บ', 'ป' , 'ผ', 'ฝ', 'พภ', 'ฟ', 'ม', 'รลฬ', 'ว', 'ศษส', 'ห', 'อ', 'ฮ']\n",
        "diphthongs = ['หร', 'หล', 'หว', 'พร', 'พล']\n",
        "vovels = ['เ', 'แ', 'ไ', 'ใ', 'โ']\n",
        "\n",
        "resultStr = \"\"\n",
        "result = []\n",
        "# words = ['ไชยบุรี', 'ชัยบุรี', 'ใชยบุรี', 'ไชบุรี']\n",
        "for word in words:\n",
        "    resultStr = \"\"\n",
        "    tokens = syllable_tokenize(word)\n",
        "    print(tokens)\n",
        "    for token in tokens:\n",
        "        searchIndex = 0\n",
        "        if token[0] == 'ห' or token[0] == 'พ':\n",
        "            resultStr = resultStr + str(diphthongs.index(token[0:2]))\n",
        "            continue\n",
        "        try:\n",
        "            if vovels.index(token[0]) >= 0:\n",
        "                searchIndex = 1\n",
        "        except:\n",
        "            pass\n",
        "        for i in range(0, len(thai_alphabet_cluster)):\n",
        "            try:\n",
        "                if thai_alphabet_cluster[i].index(token[searchIndex]) >= 0:\n",
        "                    resultStr = resultStr + str(i)\n",
        "            except:\n",
        "                pass\n",
        "    result.append(resultStr)\n",
        "print(result)\n",
        "if result == result[::-1]:\n",
        "    print(\"Same word\")\n",
        "else:\n",
        "    print(\"Not same word\")"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ไชย', 'บุ', 'รี']\n",
            "['ชัย', 'บุ', 'รี']\n",
            "['ใช', 'ยะ', 'บุ', 'รี']\n",
            "['ไช', 'บุ', 'รี']\n",
            "['61421', '61421', '681421', '61421']\n",
            "Not same word\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJKFbVy2E9Cz",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ]
}